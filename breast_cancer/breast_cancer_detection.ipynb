{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from pycaret.classification import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files = []\n",
    "labels1 = []\n",
    "dirname = '/mnt/napster_disk/ai_projects/demos/breast_cancer/mama_cancer_png'\n",
    "\n",
    "for dirname, _, filenames in os.walk(dirname):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.png'):\n",
    "            files.append(os.path.join(dirname, filename))\n",
    "            if filename.startswith('b'):\n",
    "                labels1.append('benigno')\n",
    "            elif filename.startswith('m'):\n",
    "                labels1.append('maligno')\n",
    "            elif filename.startswith('n'):\n",
    "                labels1.append('normal')\n",
    "\n",
    "combined = list(zip(files,labels1))\n",
    "np.random.shuffle(combined)\n",
    "files[:],labels1[:] = zip(*combined)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize_histograms(im): #normalizes the histogram of images\n",
    "    im1=im.copy()\n",
    "    for i in range(3):\n",
    "        imi=im[:,:,i]\n",
    "        #print(imi.shape)\n",
    "        minval=np.min(imi)\n",
    "        maxval=np.max(imi)\n",
    "        #print(minval,maxval)\n",
    "        imrange=maxval-minval\n",
    "        im1[:,:,i]=(255/(imrange+0.0001)*(imi-minval)) # imi-minval will turn the color range between 0-imrange, and the scaleing will stretch the range between 0-255\n",
    "    return im1\n",
    "\n",
    "######################################################################\n",
    "# This following function reads the images from file,\n",
    "#auto crops the image to its relevant content, then normalizes\n",
    "#the histograms of the cropped images\n",
    "######################################################################\n",
    "\n",
    "def read_and_process_image(filename):\n",
    "        im=cv2.imread(filename) #read image from file\n",
    "        # The following steps re needed for auto cropping the black paddings in the images\n",
    "\n",
    "        gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) # convert 2 grayscale\n",
    "        _,thresh = cv2.threshold(gray,10,255,cv2.THRESH_BINARY) # turn it into a binary image\n",
    "        contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE) # find contours\n",
    "        if len(contours) != 0:\n",
    "            #find the biggest area\n",
    "            cnt = max(contours, key = cv2.contourArea)\n",
    "\n",
    "            #find the bounding rect\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "            crop = im[y:y+h,x:x+w]# crop image\n",
    "            #crop1=cv2.resize(crop,(im_size,im_size)) # resize to im_size X im_size size\n",
    "            crop=normalize_histograms(crop)\n",
    "            return crop\n",
    "        else:\n",
    "            return( normalize_histograms(im))\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "#### The following functions are for extracting features from the images #########\n",
    "##################################################################################\n",
    "\n",
    "# histogram statistics (mean, standard deviations, energy, entropy, log-kurtosis)\n",
    "\n",
    "\n",
    "def histogram_statistics(hist):\n",
    "    #hist= cv2.calcHist([gr],[0],None,[256],[0,256])\n",
    "    hist=hist/np.sum(hist)#probabilities\n",
    "    hist=hist.reshape(-1)\n",
    "    hist[hist==0]=10**-20 # replace zeros with a small number\n",
    "    mn=np.sum([i*hist[i] for i in range(len(hist))]) # mean\n",
    "    std_dev=np.sqrt(np.sum([((i-mn)**2)*hist[i] for i in range(len(hist))])) # standard deviation\n",
    "    energy=np.sum([hist[i]**2 for i in range(len(hist))]) #energy\n",
    "    entropy=np.sum([hist[i]*np.log(hist[i]) for i in range(len(hist))]) #entropy\n",
    "    kurtosis=np.log(np.sum([(std_dev**-4)*((i-mn)**-4)*hist[i] for i in range(len(hist))])) # kurtosis\n",
    "    return[mn,std_dev,energy,entropy,kurtosis]\n",
    "\n",
    "#################################################################\n",
    "# create thresholding based features, the idea is to hand engineer some features based on adaptive thresholding.\n",
    "#After looking at the images it appeared  that adaptive thresholding may\n",
    "#leave different artifacts in the processed images, we can extract several features from these artifacts\n",
    "##################################################################\n",
    "\n",
    "def thresholding_based_features(im,imsize,quartiles):\n",
    "    im=cv2.resize(im,(imsize,imsize))\n",
    "    gray=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    w=11 #window\n",
    "    t=5#threshold\n",
    "    counts=[]\n",
    "    th = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,w,t) # adaptive gaussian threshold the image\n",
    "    th=cv2.bitwise_not(th)    #invert the image (the black pixels will turn white and the white pixels will turn black)\n",
    "    contours,hierarchy = cv2.findContours(th,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE) #find cntours in the image\n",
    "    #print(len(contours))\n",
    "\n",
    "    q=np.zeros(len(quartiles)) # quartiles of contours will be stored here\n",
    "\n",
    "\n",
    "    for cnt in contours:\n",
    "        area=cv2.contourArea(cnt) # calculate the area of the contours\n",
    "        if area<40000: #Exclude contours that are too big, generally these are the image outlines\n",
    "            counts.append(area)\n",
    "    if len(counts)>1:\n",
    "        q=np.quantile(np.array(counts),quartiles) # contour quartiles\n",
    "\n",
    "    return (q,len(counts),np.sum(th)/(255*th.shape[0]*th.shape[1]))# return the contour quartiles, number of contours, proportion of white pixels in the thresholded images\n",
    "    #counts.append(np.sum(th)/(normalizing_factor*(th.shape[0]*th.shape[1])))\n",
    "\n",
    "##########################################################################\n",
    "############ The following code creates the various features #############\n",
    "##########################################################################\n",
    "\n",
    "# color averages\n",
    "B=[]\n",
    "G=[]\n",
    "R=[]\n",
    "\n",
    "#mini 16 bin histograms\n",
    "hist_B=[]\n",
    "hist_G=[]\n",
    "hist_R=[]\n",
    "\n",
    "#statistics fom full 256 bin shitogram\n",
    "hist_feat_B=[]\n",
    "hist_feat_G=[]\n",
    "hist_feat_R=[]\n",
    "hist_feat_GS=[]\n",
    "\n",
    "#thresholding based features\n",
    "mean_pixels=[] #proportion of white pixels\n",
    "contour_quartiles=[] # contour area quartiles\n",
    "no_of_contours=[] #total number of contours\n",
    "\n",
    "\n",
    "quartiles=np.arange(0.1,1,0.1) # contour area quartiles\n",
    "bins=16 # mini histogram bins\n",
    "\n",
    "for f in files:\n",
    "    im=read_and_process_image(f)\n",
    "    #im_yuv = cv2.cvtColor(im, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # equalize the histogram of the Y channel\n",
    "    #im_yuv[:,:,0] = cv2.equalizeHist(im_yuv[:,:,0])\n",
    "\n",
    "    # convert the YUV image back to RGB format\n",
    "    #im = cv2.cvtColor(im_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "    #median color\n",
    "    B.append(np.median(im[:,:,0]))\n",
    "    G.append(np.median(im[:,:,1]))\n",
    "    R.append(np.median(im[:,:,2]))\n",
    "\n",
    "    #histograms\n",
    "    hist_B.append(cv2.calcHist([im],[0],None,[bins],[0,256])/(im.size/3))\n",
    "    hist_G.append(cv2.calcHist([im],[1],None,[bins],[0,256])/(im.size/3))\n",
    "    hist_R.append(cv2.calcHist([im],[2],None,[bins],[0,256])/(im.size/3))\n",
    "\n",
    "\n",
    "    #more histogram features\n",
    "\n",
    "    hist_feat_B.append(histogram_statistics(cv2.calcHist([im],[0],None,[256],[0,256])))\n",
    "    hist_feat_G.append(histogram_statistics(cv2.calcHist([im],[1],None,[256],[0,256])))\n",
    "    hist_feat_R.append(histogram_statistics(cv2.calcHist([im],[2],None,[256],[0,256])))\n",
    "\n",
    "    gr=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    gr=cv2.equalizeHist(gr)\n",
    "    hist_feat_GS.append(histogram_statistics(cv2.calcHist([gr],[0],None,[256],[0,256])))\n",
    "\n",
    "    #threshold featues\n",
    "    q,nc,m=thresholding_based_features(im,256,quartiles)\n",
    "    mean_pixels.append(m)\n",
    "    contour_quartiles.append(q)\n",
    "    no_of_contours.append(nc)\n",
    "\n",
    "#create feature vectors\n",
    "width_of_features=3*bins+len(quartiles)+2+20 #20 features are histogram statistics\n",
    "\n",
    "X=np.zeros((len(files),width_of_features)) # this is where all features will be stored\n",
    "\n",
    "for i in range(len(files)):\n",
    "    X[i,0:bins]=hist_B[i].reshape(-1)\n",
    "    X[i,bins:2*bins]=hist_G[i].reshape(-1)\n",
    "    X[i,2*bins:3*bins]=hist_R[i].reshape(-1)\n",
    "    X[i,3*bins:3*bins+len(quartiles)]=contour_quartiles[i].reshape(-1)\n",
    "    X[i,3*bins+len(quartiles)]=mean_pixels[i]\n",
    "    X[i,3*bins+len(quartiles)+1]=no_of_contours[i]\n",
    "    start=3*bins+len(quartiles)+2\n",
    "    X[i,start:start+5]=hist_feat_B[i]\n",
    "    X[i,start+5:start+10]=hist_feat_G[i]\n",
    "    X[i,start+10:start+15]=hist_feat_R[i]\n",
    "    X[i,start+15:start+20]=hist_feat_B[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_labels = pd.DataFrame(labels1)\n",
    "df_labels = df_labels.rename(columns={0: 'Label'})\n",
    "\n",
    "df_data = pd.DataFrame(X)\n",
    "full_data = pd.concat([df_labels, df_data], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_reg = setup(full_data, target='Label')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = compare_models()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc_model = create_model('rf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc_evaluate = evaluate_model(rfc_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calibrated_model = calibrate_model(rfc_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_model(calibrated_model, 'breast_cancer_model')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}